{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import glob\n",
    "from xlrd import open_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "sys.path.append('../')\n",
    "from util.calc_util import split_train_and_test_data\n",
    "from util.cfg import config\n",
    "from util.file_util import mkdirs_if_not_exist, out_result, prepare_scutfbp5500\n",
    "from util.vgg_face_feature import extract_feature\n",
    "\n",
    "def ecust_train_and_test_set():\n",
    "    \"\"\"\n",
    "    split train and test eccv dataset\n",
    "    :param split_csv_filepath:\n",
    "    :return:\n",
    "    :Version:1.0\n",
    "    \"\"\"\n",
    "    \n",
    "    DATA_DIR = '/home/ubuntu/10_crop/'\n",
    "    LABELS_FILE = '/home/ubuntu/ECUST_FBP/scores/private_generic_all.xlsx'\n",
    "    \n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    wb=open_workbook(LABELS_FILE)\n",
    "    ws = wb.sheet_by_index(0)\n",
    "    \n",
    "    labels_dict = {}\n",
    "\n",
    "    for i in range(ws.nrows-1):\n",
    "       #print(ws.cell(i+1,0).value) \n",
    "       img = str(ws.cell(i+1,1).value)+'.jpg'\n",
    "       label = ws.cell(i+1,2).value\n",
    "       labels_dict[img] = float(label)\n",
    "     \n",
    "    labels_dict_new = {}\n",
    "    for root, dirs, files in os.walk(DATA_DIR):\n",
    "     for file in files: \n",
    "        \n",
    "        f = os.path.join(root, file)\n",
    "        labels_dict_new[f] = 5\n",
    "        if file in labels_dict:\n",
    "  \n",
    "           X.append(f)\n",
    "           y.append(labels_dict[os.path.split(f)[-1]])   \n",
    "    return labels_dict_new, labels_dict_new       \n",
    "\n",
    "train,test = ecust_train_and_test_set()\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/10_crop/gustavo-souza-niWXJ9MAozQ-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/gustavo-souza-f9UqUexxhrE-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/ahmad-qime-GYbBstR60Bw-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/tobi-oshinnaike-Z7MKNGFnbOw-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/gregory-buzdyk-bdbC8RlXSUU-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/kamal-alkhatib-IETO_Z0BrsE-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/kamal-alkhatib-i4ls_N9o968-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/joshua-purnell-kz6qS9mWbAo-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/farhan-faras-Pu_87ZZO6Yg-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/bulbul-ahmed-g70f1GaqBhc-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/sonny-mauricio-dH3g3KLaq5s-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/martin-magnemyr-V4B0nrIJcls-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/kamran-ch-7pES3XC7l7Q-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/moein-rahmani-A3802JoFGqg-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/gustavo-souza-niWXJ9MAozQ-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/gustavo-souza-f9UqUexxhrE-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/ahmad-qime-GYbBstR60Bw-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/tobi-oshinnaike-Z7MKNGFnbOw-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/gregory-buzdyk-bdbC8RlXSUU-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/kamal-alkhatib-IETO_Z0BrsE-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/kamal-alkhatib-i4ls_N9o968-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/joshua-purnell-kz6qS9mWbAo-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/farhan-faras-Pu_87ZZO6Yg-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/bulbul-ahmed-g70f1GaqBhc-unsplash (1).jpg 5\n",
      "/home/ubuntu/10_crop/sonny-mauricio-dH3g3KLaq5s-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/martin-magnemyr-V4B0nrIJcls-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/kamran-ch-7pES3XC7l7Q-unsplash.jpg 5\n",
      "/home/ubuntu/10_crop/moein-rahmani-A3802JoFGqg-unsplash.jpg 5\n",
      "[array([-0.        , -0.        ,  0.91262937, ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([-0.      , -0.      , 49.199505, ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([56.640347, -0.      , -0.      , ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([ 3.742893, -0.      , -0.      , ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([89.11164, -0.     , -0.     , ..., -0.     , -0.     , -0.     ],\n",
      "      dtype=float32), array([18.142008, -0.      , -0.      , ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([37.066635, -0.      , -0.      , ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32)]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 300. GiB for an array with shape (200704, 200704) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0d57ef47bf25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mmkdirs_if_not_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eccv_fbp_reg_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sklearn/linear_model/_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    285\u001b[0m         scaled_sigma_ = np.dot(Vh.T,\n\u001b[1;32m    286\u001b[0m                                Vh / (eigen_vals_ +\n\u001b[0;32m--> 287\u001b[0;31m                                      lambda_ / alpha_)[:, np.newaxis])\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscaled_sigma_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 300. GiB for an array with shape (200704, 200704) and data type float64"
     ]
    }
   ],
   "source": [
    "    from keras.engine import  Model\n",
    "    from keras.layers import Input\n",
    "    from keras_vggface.vggface import VGGFace\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    from keras_vggface.vggface import VGGFace\n",
    "    from keras_vggface import utils\n",
    "    vgg_model = VGGFace() # pooling: None, avg or max\n",
    "# Layer Features\n",
    "\n",
    "    def extract_feature_new(file, layer_name):\n",
    "   \n",
    "        out = vgg_model.get_layer(layer_name).output\n",
    "        vgg_model_new = Model(vgg_model.input, out)\n",
    "        img = image.load_img(file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = utils.preprocess_input(x, version=1) # or version=2\n",
    "        features = vgg_model_new.predict(x)\n",
    "        return features.ravel()\n",
    "\n",
    "    train_vec = list()\n",
    "    train_label = list()\n",
    "    test_vec = list()\n",
    "    test_label = list()\n",
    "\n",
    "    for k, v in train.items():\n",
    "        feature = np.concatenate((extract_feature_new(k, layer_name=\"conv5_2\"), extract_feature_new(k, layer_name=\"conv5_3\")),\n",
    "                                 axis=0)\n",
    "        train_vec.append(feature)\n",
    "        train_label.append(v)\n",
    "        print(k,v)\n",
    "    for k, v in test.items():\n",
    "        feature = np.concatenate((extract_feature_new(k, layer_name=\"conv5_2\"), extract_feature_new(k, layer_name=\"conv5_3\")),\n",
    "                                 axis=0)\n",
    "        test_vec.append(feature)\n",
    "        test_label.append(v)\n",
    "        print(k,v)\n",
    "    print(train_vec)    \n",
    "    reg = linear_model.BayesianRidge()\n",
    "    reg.fit(np.array(train_vec), np.array(train_label))\n",
    "    mkdirs_if_not_exist('./model')\n",
    "    joblib.dump(reg, config['eccv_fbp_reg_model'])\n",
    "\n",
    "    predicted_label = reg.predict(np.array(test_vec))\n",
    "    mae_lr = round(mean_absolute_error(np.array(test_label), predicted_label), 4)\n",
    "    rmse_lr = round(math.sqrt(mean_squared_error(np.array(test_label), predicted_label)), 4)\n",
    "    pc = round(np.corrcoef(test_label, predicted_label)[0, 1], 4)\n",
    "\n",
    "    print('===============The Mean Absolute Error of Model is {0}===================='.format(mae_lr))\n",
    "    print('===============The Root Mean Square Error of Model is {0}===================='.format(rmse_lr))\n",
    "    print('===============The Pearson Correlation of Model is {0}===================='.format(pc))\n",
    "\n",
    "    csv_tag = time.time()\n",
    "\n",
    "    mkdirs_if_not_exist('./result')\n",
    "    df = pd.DataFrame([mae_lr, rmse_lr, pc])\n",
    "    df.to_csv('./result/performance_%s.csv' % csv_tag, index=False)\n",
    "\n",
    "    out_result(list(test.keys()), predicted_label.flatten().tolist(), test_label, None,\n",
    "               path='./result/detail_%s.csv' % csv_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
